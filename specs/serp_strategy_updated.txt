# The Complete AI-Powered SEO Arbitrage Strategy

## 1. Objective

To create a script that automates the discovery, validation, and strategic planning of high-opportunity keywords for a local business. This process is fully independent of Serpstat, using a combination of the **Serper API** and the **SEO Review Tools API**. The final output is a prioritized "Content Blueprint" ready for an AI blog writing agent.

## 2. Required Toolkit & Setup

*   **SERP API:** Your Serper account (`https://google.serper.dev/search`).
*   **Keyword & Authority API:** Your SEO Review Tools account (`https://api.seoreviewtools.com/`).
*   **Environment:** A TypeScript/Node.js environment with `node-fetch` or a similar HTTP client installed.

---

## Phase 0: Initialization

*   **Action:** Define initial inputs and data structures.
*   **Code Sample:**
    ```typescript
    // --- CONFIGURATION ---
    const CATEGORY = "plumbing";
    const LOCATION = "orlando fl";
    const SEARCH_ENGINE_PARAMS = { gl: "us", hl: "en" }; // For Serper
    const KEYWORD_STATS_LOCATION = "United States"; // For SEO Review Tools
    const KEYWORD_STATS_LANGUAGE = "English"; // For SEO Review Tools

    // --- DATA STORES ---
    let keywordUniverse: Set<string> = new Set();
    let promisingKeywords: any[] = [];
    let highPotentialKeywords: any[] = [];
    let validatedKeywords: any[] = [];
    let contentPlan: any[] = [];

    // --- SEED KEYWORDS ---
    const seedKeywords = [
      `${CATEGORY} ${LOCATION}`,
      `${LOCATION} ${CATEGORY}`,
      `emergency ${CATEGORY} ${LOCATION}`
    ];
    ```

---

## Phase 1: Keyword Universe Expansion

*   **Goal:** Generate a large, unique list of potential keywords.
*   **Action:** Use Serper to find related searches and questions for each seed keyword.

*   **Code Sample:**
    ```typescript
    async function expandKeywords(seeds: string[], serperApiKey: string): Promise<Set<string>> {
      const universe = new Set<string>(seeds);
      const myHeaders = new Headers({
        "X-API-KEY": serperApiKey,
        "Content-Type": "application/json",
      });

      for (const seed of seeds) {
        const raw = JSON.stringify({ q: seed, ...SEARCH_ENGINE_PARAMS });
        const requestOptions: RequestInit = { method: "POST", headers: myHeaders, body: raw };

        try {
          const response = await fetch("https://google.serper.dev/search", requestOptions);
          const result = await response.json();

          if (result.relatedSearches) {
            result.relatedSearches.forEach((item: any) => universe.add(item.query));
          }
          if (result.peopleAlsoAsk) {
            result.peopleAlsoAsk.forEach((item: any) => universe.add(item.question));
          }
        } catch (error) {
          console.error(`Failed to expand keyword: ${seed}`, error);
        }
        // Add a small delay to be respectful to the API
        await new Promise(resolve => setTimeout(resolve, 250));
      }
      return universe;
    }
    ```
*   **Sample Result (`keywordUniverse`):**
    ```json
    [
      "plumbing orlando",
      "orlando plumber",
      "emergency plumber orlando",
      "plumbers in orlando fl",
      "best plumbers in orlando",
      "how much do plumbers charge in florida",
      // ...and hundreds more...
    ]
    ```

---

## Phase 2: Enrichment & Initial Filtering

*   **Goal:** Get core metrics for all keywords and filter out the weakest ones.
*   **Action:** Use the SEO Review Tools `keyword-statistics` endpoint.

*   **Code Sample:**
    ```typescript
    async function getBulkKeywordMetrics(keywords: string[], apiKey: string): Promise<any[]> {
      const url = `https://api.seoreviewtools.com/keyword-statistics/?location=${encodeURIComponent(KEYWORD_STATS_LOCATION)}&hl=${encodeURIComponent(KEYWORD_STATS_LANGUAGE)}&key=${apiKey}`;
      const response = await fetch(url, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ keywords }),
      });
      const result = await response.json();
      return result.data?.data || [];
    }

    // --- Filtering Logic ---
    const enrichedKeywords = await getBulkKeywordMetrics(Array.from(keywordUniverse), 'YOUR_API_KEY');

    promisingKeywords = enrichedKeywords.filter(kw => kw.search_volume >= 20);
    ```
*   **Sample Result (`promisingKeywords`):**
    ```json
    [
      {
        "keyword": "plumbers in orlando fl",
        "search_volume": 4400,
        "cpc": 20.12,
        // ...other metrics
      },
      {
        "keyword": "emergency plumber orlando",
        "search_volume": 320,
        "cpc": 29.44,
        // ...other metrics
      }
    ]
    ```

---

## Phase 2.5: Pre-Qualification Ranking

*   **Goal:** Score and rank the promising keywords to find the top 20 candidates for the expensive deep analysis.
*   **Action:** Calculate a `preQualScore` for each keyword.

*   **Code Sample:**
    ```typescript
    function preQualifyKeywords(keywords: any[]): any[] {
      const scoredKeywords = keywords.map(item => {
        // We lack a 'difficulty' score, so we'll use 'competition' (0-1 scale) as a proxy.
        const safeCompetition = (item.competition > 0) ? item.competition : 0.01;
        const volumeScore = Math.log10(item.search_volume);
        const safeCost = item.cpc > 0 ? item.cpc : 0.1;

        // Score now balances volume, commercial value, and paid competition.
        const preQualScore = (volumeScore * safeCost) / safeCompetition;
        return { ...item, preQualScore };
      });

      // Sort by the new score and return the top 20
      return scoredKeywords.sort((a, b) => b.preQualScore - a.preQualScore).slice(0, 20);
    }

    highPotentialKeywords = preQualifyKeywords(promisingKeywords);
    ```
*   **Sample Result (`highPotentialKeywords`):** A sorted array of the top 20 keyword objects, each with a `preQualScore`.

---

## Phase 3: Deep Analysis and Validation

*   **Goal:** Analyze the SERP for the top 20 keywords, calculate our artificial difficulty score, and validate them.

*   **Code Sample (Orchestrator):**
    ```typescript
    async function runDeepAnalysis(keywords: any[], serperKey: string, srtKey: string): Promise<any[]> {
        const validated = [];
        const megaSites = ["yelp.com", "homeadvisor.com", "forbes.com", "wikipedia.org", "reddit.com"];

        for (const keyword of keywords) {
            try {
                // Step 3.2: Get SERP data from Serper
                const serperResponse = await serper.search(keyword.keyword); // Assuming a serper client
                const competitorUrls = serperResponse.organic.slice(0, 10).map((r: any) => r.link);

                // Step 3.3: Get Authority data from SEO Review Tools
                const authorityResponse = await getAuthorityScores(competitorUrls, srtKey);
                const authorityData = Object.values(authorityResponse.data.data);

                // Calculate metrics
                const avg_da_top_10 = authorityData.reduce((acc, curr) => acc + curr["Domain Authority"], 0) / authorityData.length;
                const avg_pa_top_10 = authorityData.reduce((acc, curr) => acc + curr["Page Authority"], 0) / authorityData.length;
                const mega_site_score = serperResponse.organic.slice(0, 5)
                    .filter((r: any) => megaSites.includes(new URL(r.link).hostname.replace('www.', '')))
                    .length * 20;

                // Step 3.4: Calculate Artificial Difficulty
                const artificial_difficulty = (0.5 * avg_da_top_10) + (0.3 * avg_pa_top_10) + (0.2 * mega_site_score);

                // Step 3.5: Apply Rejection Filter
                if (artificial_difficulty <= 40) { // Our final check
                    validated.push({
                        ...keyword,
                        artificial_difficulty,
                        serp_analysis: {
                            average_da_top_10: avg_da_top_10,
                            average_pa_top_10: avg_pa_top_10,
                            mega_site_score: mega_site_score / 20, // store the count, not the score
                            competitor_urls: competitorUrls,
                            questions_to_answer: serperResponse.peopleAlsoAsk?.map((p: any) => p.question) || []
                        }
                    });
                }
            } catch (error) {
                console.error(`Failed deep analysis for "${keyword.keyword}"`, error);
            }
            // THE CRUCIAL 1-SECOND DELAY
            await new Promise(resolve => setTimeout(resolve, 1000));
        }
        return validated;
    }

    validatedKeywords = await runDeepAnalysis(highPotentialKeywords, 'YOUR_SERPER_KEY', 'YOUR_SRT_KEY');
    ```
*   **Sample Result (`validatedKeywords`):** An array of fewer than 20 fully-enriched objects, each now containing an `artificial_difficulty` score and a `serp_analysis` object.

---

## Phase 4 & 5: Blueprint Creation & Iteration

*   **Goal:** Group validated keywords into actionable content clusters.

*   **Code Sample Snippet (Clustering and Final Scoring):**
    ```typescript
    function createContentBlueprint(keywords: any[]): any[] {
        // First, calculate the final arbitrage score for all validated keywords
        keywords.forEach(kw => {
            const volumeScore = Math.log10(kw.region_queries_count);
            const cpcScore = kw.cpc > 0 ? kw.cpc : 0.1;
            // The final score heavily rewards low artificial difficulty
            kw.arbitrage_score = (volumeScore * cpcScore) / kw.artificial_difficulty;
        });

        // Sort by the final score to find the best primary keywords
        const sortedKeywords = keywords.sort((a, b) => b.arbitrage_score - a.arbitrage_score);

        // ... (Implement thematic clustering logic here) ...

        // For the demo, we'll just format the top validated keyword
        const topKeyword = sortedKeywords;
        const blueprint = {
            cluster_rank: 1,
            cluster_title: `Guide to ${topKeyword.keyword}`,
            cluster_opportunity_score: topKeyword.arbitrage_score,
            content_brief: {
                primary_keyword: topKeyword.keyword,
                secondary_keywords: [], // To be populated by clustering
                supporting_keywords: [], // To be populated by clustering
                user_intent: topKeyword.intents.includes("C") ? "Commercial" : "Transactional",
                questions_to_answer: topKeyword.serp_analysis.questions_to_answer,
                competitor_urls_to_analyze: topKeyword.serp_analysis.competitor_urls,
            },
            // ... (metadata)
        };

        return [blueprint]; // Return an array of blueprints
    }

    contentPlan = createContentBlueprint(validatedKeywords);
    ```
*   **Final Output (`contentPlan`):** This will be the final, rich JSON object as defined in our previous discussions, ready to be passed to the next agent.